{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Notebook\n",
    "\n",
    "This notebook contains the processes for cleaning, imputation, and labeling of the data.\n",
    "\n",
    "**Note:** The preprocessing steps can be modified based on the specific data and labeling criteria.\n",
    "Author: Fatemeh Salehi (fatemeh.salehihafshejani@fau.de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fatemehsalehi/opt/anaconda3/envs/RAproject/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "from pandas import read_csv\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import csv\n",
    "import datetime\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.calibration import calibration_curve, CalibrationDisplay\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from utils import *\n",
    "import torch\n",
    "import wget\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "# manual nested cross-validation for random forest on a classification dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "#matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "pd.set_option ('display.max_columns' , None)\n",
    "pd.set_option ('display.max_columns' , 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bDMARD.csv', delimiter=';')\n",
    "df = df.replace(to_replace=',', value='.', regex=True)\n",
    "df = df.replace({'every x days': 'x times a day', 'every x weeks': 'x times a week'})\n",
    "\n",
    "# Convert Visit_date to datetime\n",
    "df['Visit_date'] = pd.to_datetime(df['Visit_date'], errors='coerce')\n",
    "\n",
    "# Remove NaN values in Visit_date\n",
    "df = df[df['Visit_date'].notna()]\n",
    "\n",
    "# Sort df based on tptID and Visit_date\n",
    "df.sort_values(by=['tptID', 'Visit_date'], inplace=True)\n",
    "\n",
    "# Map gender to 0/1\n",
    "df['Gender'] = df['Gender'].map(dict(f=1, m=0))\n",
    "\n",
    "# Find columns containing 'yes' or 'no'\n",
    "df_columns_yn = df.columns[df.isin(['yes', 'no']).any()]\n",
    "# Convert 'yes', 'no' to 0, 1\n",
    "for col_d in df_columns_yn:\n",
    "    df[col_d] = df[col_d].map(dict(yes=1, no=0))\n",
    "\n",
    "# List of diseases\n",
    "list_disease = ['Osteoarthritis', 'Asthma', 'Uveitis', 'Hypertension', 'Chronic_renal_insufficiency', 'COPD', 'Depression', 'Diabetes', 'Inflammatory_bowel_disease', 'Fat_metabolism_disorder', 'Gout', 'Heart_attack', 'Coronary_heart_disease', 'Osteoporosis', 'Periodontitis', 'Thyroid_disease', 'Thrombosis']\n",
    "\n",
    "# Delete rows before the first taking bDMARD\n",
    "df = df.groupby('tptID', group_keys=False).apply(lambda x: x.loc[x['bDMARD'].notna().idxmax():]).reset_index(drop=True)\n",
    "\n",
    "# Find interval between visit_date based on day (consecutive rows)\n",
    "df['DateDiff'] = df.groupby('tptID', group_keys=False)['Visit_date'].diff().apply(lambda x: x.days)\n",
    "\n",
    "# Find interval between visit_date based on first visit_date for each group\n",
    "df['DateDiff_N'] = df.groupby('tptID', group_keys=False)['Visit_date'].apply(lambda x: (x - x.min()))\n",
    "\n",
    "# Find interval between visit_date based on month (first visit_date for each group)\n",
    "df['DateDiff_NM'] = df.groupby('tptID', group_keys=False)['Visit_date'].apply(lambda x: (x - x.min()).dt.days / 30.44)\n",
    "\n",
    "# Optional: Round the result to a specific number of decimal places, if desired\n",
    "df['DateDiff_NM'] = df['DateDiff_NM'].round(1)\n",
    "\n",
    "# Setting 0 for before and 1 for after the first announcement of disease\n",
    "def set_disease(df, disease):\n",
    "    for col in disease:\n",
    "        if not df[df[col] == 1].empty:\n",
    "            idx = df[df[col] == 1].index[0]\n",
    "            df.loc[idx:, col] = 1\n",
    "            df.loc[:idx, col] = 0\n",
    "        else:\n",
    "            df[col] = 0\n",
    "    return df\n",
    "\n",
    "# Apply set_disease for each group\n",
    "df = df.groupby('tptID', group_keys=False).apply(lambda x: set_disease(x, list_disease))\n",
    "\n",
    "# Fill NaN for Height and Weight\n",
    "df[['Height_cm', 'Weight_kg']] = df.groupby('tptID', group_keys=False)[['Height_cm', 'Weight_kg']].apply(lambda x: x.ffill())\n",
    "df[['Height_cm', 'Weight_kg']] = df.groupby('tptID', group_keys=False)[['Height_cm', 'Weight_kg']].apply(lambda x: x.bfill())\n",
    "\n",
    "# For patients whose weight and height information is unavailable, use average values\n",
    "df['Height_cm'] = np.where((df['Height_cm'].isnull()) & (df['Gender'] == 0), 177, df['Height_cm'])\n",
    "df['Height_cm'] = np.where((df['Height_cm'].isnull()) & (df['Gender'] == 1), 165, df['Height_cm'])\n",
    "df['Weight_kg'] = np.where((df['Weight_kg'].isnull()) & (df['Gender'] == 0), 86, df['Weight_kg'])\n",
    "df['Weight_kg'] = np.where((df['Weight_kg'].isnull()) & (df['Gender'] == 1), 76, df['Weight_kg'])\n",
    "\n",
    "# Converting receiving Medicine to 0/1\n",
    "df['bDMARD'] = np.where(~df['bDMARD'].isnull(), 1, 0)\n",
    "df['tsDMARD'] = np.where(~df['tsDMARD'].isnull(), 1, 0)\n",
    "df['csDMARD'] = np.where(~df['csDMARD'].isnull(), 1, 0)\n",
    "\n",
    "# Change object dtype to float\n",
    "dtype_object = ['Weight_kg', 'HAQ_Score', 'DAS28BSG_Score', 'DAS28CRP_Score', 'CDAI_Score', 'SDAI_Score', 'CRP_mg_l', 'RF', 'CCP', 'bDMARD', 'bDMARD_dose_mg', 'tsDMARD', 'tsDMARD_dose_mg', 'tsDMARD_interval', 'csDMARD', 'csDMARD_dose_mg', 'csDMARD_interval', 'Prednisolone_dose_current_mg', 'Prednisolone_dose_long-term_mg']\n",
    "for dt in dtype_object:\n",
    "    df[dt] = df[dt].astype(float)\n",
    "\n",
    "#df_1_columns = ['DAS28CRP_Score','tsDMARD','tsDMARD_dose_mg','tsDMARD_interval','tsDMARD_interval_unit','csDMARD', 'csDMARD_dose_mg', 'csDMARD_interval','csDMARD_interval_unit']\n",
    "#df_columns_fill = [item for item in df.columns if item not in df_1_columns]\n",
    "\n",
    "#df[df_columns_fill] = df.groupby('tptID', group_keys=False)[df_columns_fill].apply(lambda x: x.ffill())\n",
    "#df[df_columns_fill] = df.groupby('tptID', group_keys=False)[df_columns_fill].apply(lambda x: x.bfill())\n",
    "\n",
    "# Change values of RF, CRP, CCP to 0 or 1\n",
    "df['CRP_mg_l'] = np.where(df['CRP_mg_l'] < 5.2, 0, 1)\n",
    "df['RF_b'] = np.where(df['RF'] < 20, 0, 1)\n",
    "df['CCP_b'] = np.where(df['CCP'] < 14, 0, 1)\n",
    "\n",
    "# CCP should be considered 1 after the first time becoming 1 (positive)\n",
    "def set_CCP(df, column):\n",
    "    for col in column:\n",
    "        if not df[df[col] == 1].empty:\n",
    "            idx = df[df[col] == 1].index[0]\n",
    "            df.loc[idx:, col] = 1\n",
    "    return df\n",
    "\n",
    "df = df.groupby('tptID', group_keys=False).apply(lambda x: set_CCP(x, ['CCP']))\n",
    "\n",
    "# Fill NaN as 0 for medicine_dose and interval that the medicine not taken\n",
    "medicine_cs_ts = ['csDMARD', 'tsDMARD']\n",
    "for i in medicine_cs_ts:\n",
    "    df[f'{i}_dose_mg'] = np.where(df[i] == 0, df[f'{i}_dose_mg'].fillna(0), df[f'{i}_dose_mg'])\n",
    "    df[f'{i}_interval'] = np.where(df[i] == 0, df[f'{i}_interval'].fillna(0), df[f'{i}_interval'])\n",
    "    df[f'{i}_interval_unit'] = np.where(df[i] == 0, df[f'{i}_interval_unit'].fillna(0), df[f'{i}_interval_unit'])\n",
    "\n",
    "# Calculate total medicine_dose within a week\n",
    "medicine = ['bDMARD', 'csDMARD', 'tsDMARD']\n",
    "for i in medicine:\n",
    "    conditions = [df[f'{i}_interval_unit'].str.contains('day', na=False), df[f'{i}_interval_unit'].str.contains('week', na=False), df[f'{i}_interval_unit'] == 0]\n",
    "    choices = [df[f'{i}_dose_mg'] * df[f'{i}_interval'] * 7, df[f'{i}_dose_mg'] * df[f'{i}_interval'], 0]\n",
    "    df[f'{i}_dose_mg_week'] = np.select(conditions, choices)\n",
    "\n",
    "df['BMI'] = df['Weight_kg'] / ((df['Height_cm'] / 100) ** 2)\n",
    "df.rename(columns = {'DAS28BSG_Score':'DAS28ESR_Score'}, inplace = True)\n",
    "\n",
    "            \n",
    "#df.drop(columns=['Weight_kg','Height_cm', 'DateDiff', 'DateDiff_N','Prednisolone_dose_current_mg','bDMARD_dose_mg_week', 'csDMARD_dose_mg_week','tsDMARD_dose_mg_week','bDMARD_interval', 'bDMARD_interval_unit', 'csDMARD_interval','csDMARD_interval_unit','bDMARD_dose_mg','csDMARD_dose_mg','RF_unit', 'CCP_unit'],inplace=True)\n",
    "df = df.drop(['Weight_kg','Height_cm', 'DateDiff', 'DateDiff_N','Prednisolone_dose_current_mg',\n",
    "                     'bDMARD_dose_mg_week', 'csDMARD_dose_mg_week','tsDMARD_dose_mg_week','bDMARD_interval', \n",
    "                     'bDMARD_interval_unit', 'csDMARD_interval','csDMARD_interval_unit','bDMARD_dose_mg',\n",
    "                     'Visit_date','csDMARD_dose_mg','RF_unit', 'CCP_unit','tsDMARD_interval_unit','Prednisolone_dose_long-term_mg'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Imputer with adjusted parameters\n",
    "iter_imputer = IterativeImputer(max_iter=1000, tol=0.001)  # Adjust the values as needed\n",
    "\n",
    "# Fitting and transforming the dataset with the imputer\n",
    "df_imp = iter_imputer.fit_transform(df)\n",
    "df_imputed = pd.DataFrame(df_imp, columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sustained Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_new = pd.DataFrame()\n",
    "data_f = df_imputed.groupby('tptID')\n",
    "\n",
    "l = []\n",
    "\n",
    "for key_first in data_f.groups.keys():\n",
    "    data_gr = data_f.get_group(key_first).reset_index()\n",
    "\n",
    "    if len(data_gr) >= 3:\n",
    "        for i in range(len(data_gr) - 3):\n",
    "            if data_gr.loc[i, 'DateDiff_NM'] > 6:\n",
    "                counter = 0\n",
    "                n = 0\n",
    "                if not pd.isna(data_gr.loc[i, 'DAS28ESR_Score']) and not pd.isna(data_gr.loc[i+1, 'DAS28ESR_Score']):\n",
    "                    if (data_gr.loc[i+1, 'DateDiff_NM'] - data_gr.loc[i, 'DateDiff_NM']) <= 6:\n",
    "                        if data_gr.loc[i, 'DAS28ESR_Score'] < 3.2 and data_gr.loc[i+1, 'DAS28ESR_Score'] < 3.2:\n",
    "                            n += 1\n",
    "                        counter += 1\n",
    "    else:\n",
    "        data_gr.loc[i, 'sustained'] = 0\n",
    "\n",
    "    if n == counter:\n",
    "        data_gr.loc[:, 'sustained'] = 1\n",
    "        l.append(key_first)\n",
    "    else:\n",
    "        data_gr.loc[:, 'sustained'] = 0\n",
    "\n",
    "    data_new = pd.concat([data_new, data_gr], ignore_index=True)\n",
    "\n",
    "# Output data_new to check the results\n",
    "print(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data to different category based on their month of visit\n",
    "dataset_three_months=dataset[dataset.DateDiff_NM <=3]\n",
    "dataset_six_months=dataset[dataset.DateDiff_NM <=6]\n",
    "dataset_nine_months=dataset[dataset.DateDiff_NM <=9]\n",
    "dataset_twelve_months=dataset[dataset.DateDiff_NM <=12]\n",
    "dataset_fifteen_months=dataset[dataset.DateDiff_NM <=15]\n",
    "dataset_eighteen_months=dataset[dataset.DateDiff_NM <=18]\n",
    "dataset_twentyone_months=dataset[dataset.DateDiff_NM <=21]\n",
    "dataset_twentyfour_months=dataset[dataset.DateDiff_NM <=24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out remission and effectivenss using EULAR criteria\n",
    "def labeling(dataset):\n",
    "    data_g = dataset.groupby('tptID')\n",
    "    data_new = pd.DataFrame(columns=dataset.columns)\n",
    "\n",
    "    for c_key in data_g.groups.keys():\n",
    "        data_group = data_g.get_group(c_key).reset_index()\n",
    "        if len(data_group) > 1:\n",
    "            del_das = data_group['DAS28ESR_Score'].iloc[0] - data_group['DAS28ESR_Score'].iloc[-1]\n",
    "            data_group.loc[0, 'del_das'] = del_das\n",
    "            das_current = data_group['DAS28ESR_Score'].iloc[-1]\n",
    "\n",
    "            if del_das < 1.2:\n",
    "                data_group.loc[0, 'effect_n'] = 0  # working with the criteria of this article 'cite 27'\n",
    "            else:\n",
    "                data_group.loc[0, 'effect_n'] = 1\n",
    "\n",
    "            if das_current < 2.6:\n",
    "                data_group.loc[0, 'remission'] = 1\n",
    "                data_group.loc[0, 'effectiveness'] = 1  # Effectiveness: Remission and Low Disease Activity\n",
    "            else:\n",
    "                data_group.loc[0, 'remission'] = 0\n",
    "                if das_current <= 3.2:\n",
    "                    data_group.loc[0, 'effectiveness'] = 1\n",
    "                else:\n",
    "                    data_group.loc[0, 'effectiveness'] = 0\n",
    "\n",
    "            data_new = pd.concat([data_new, data_group.iloc[[0]]], ignore_index=True)\n",
    "\n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the endpoint is 6 months\n",
    "data_new_six=data_new[data_new.DateDiff_NM <=6]\n",
    "\n",
    "dataset_new_six=labeling(data_new_six)\n",
    "\n",
    "dataset_new_six=dataset_new_six.reset_index(drop=True)\n",
    "\n",
    "#keep the sustained as zero for patients who did not have effectiveness label\n",
    "for row in range (len (dataset_new_six)-1):\n",
    "    if  (dataset_new_six.loc[row,'effectiveness'].any())==0:\n",
    "        if (dataset_new_six.loc[row,'sustained']==1):\n",
    "            (dataset_new_six.loc[row,'sustained'])=0\n",
    "data_clean= dataset_new_six.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
